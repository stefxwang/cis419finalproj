{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = json.load(open('modified_Data_1.json'))[\"data\"]\n",
    "liwc_ids = np.genfromtxt('liwc_Data.csv', delimiter=',',usecols=(0),dtype=None).tolist()\n",
    "liwc_data = np.genfromtxt('liwc_Data_noID.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawIds = list()\n",
    "Y = list()\n",
    "'''just removing \"\\xef\\xbb\\xbf\" from the first ID'''\n",
    "liwc_ids[0] = '966590693376781_1502441776458334'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3371, 49247)\n"
     ]
    }
   ],
   "source": [
    "'''there are 3371 rows in raw data and 2971 rows, 93 cols with messages (LIWC)\n",
    "from raw data, we need dayofweek, month for X and likes for Y'''\n",
    "picW = 128\n",
    "picH = 128\n",
    "numPixels = picW * picH\n",
    "channels = 3\n",
    "rawX = np.zeros((len(rawdata), 95 + picW*picH*channels))\n",
    "print(rawX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(rawdata)):\n",
    "    postID = rawdata[i]['id']\n",
    "    picFileName = rawdata[i]['picFileName']\n",
    "    rawIds.append(postID)\n",
    "    rawX[i][0] = rawdata[i]['dayofweek']\n",
    "    rawX[i][1] = rawdata[i]['month']\n",
    "    if(postID in liwc_ids) :\n",
    "        rawX[i][2:95] = liwc_data[liwc_ids.index(postID)]\n",
    "    if(picFileName != '') :\n",
    "        img = Image.open('Resized Pics 128x128/'+picFileName).load()\n",
    "        for imgX in range (picW):\n",
    "            for imgY in range (picH):\n",
    "                px = img[imgX, imgY]\n",
    "                if type(px) is int : r = g = b = px\n",
    "                elif len(px) is 3 : r, g, b = px\n",
    "                else : r, g, b, _ = px\n",
    "                baseIdx = 95 + imgX * picH + imgY\n",
    "                rawX[i][baseIdx] = r\n",
    "                rawX[i][baseIdx + numPixels] = g\n",
    "                rawX[i][baseIdx + numPixels + numPixels] = b\n",
    "    if(rawdata[i]['likes'] < 100):\n",
    "        Y.append(0)\n",
    "    else:\n",
    "        Y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3371\n",
      "(3371, 49247)\n",
      "3371\n",
      "(3371, 95)\n"
     ]
    }
   ],
   "source": [
    "print(len(rawIds))\n",
    "print(rawX.shape)\n",
    "print(len(Y))\n",
    "print(rawX[:,:95].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''split data'''\n",
    "trainIDs, testIDs, Xtrain_nonimg, Xtest_nonimg, ytrain_nonimg, ytest_nonimg = train_test_split(rawIds, rawX[:,:95], Y, test_size=0.2, random_state=420)\n",
    "\n",
    "trainIDs, testIDs, Xtrain_img, Xtest_img, ytrain_img, ytest_img = train_test_split(rawIds, rawX[:,95:], Y, test_size=0.2, random_state=420)\n",
    "\n",
    "'''standardize and normalize'''\n",
    "normalizer1 = Normalizer()\n",
    "scaler1 = StandardScaler()\n",
    "\n",
    "normalizer2 = Normalizer()\n",
    "scaler2 = StandardScaler()\n",
    "\n",
    "scaler1.fit(Xtrain_nonimg)\n",
    "normalizer1.fit(Xtrain_nonimg)\n",
    "scaler2.fit(Xtrain_img)\n",
    "normalizer2.fit(Xtrain_img)\n",
    "\n",
    "Xtrain_nonimg = scaler1.transform(Xtrain_nonimg)\n",
    "Xtrain_nonimg = normalizer1.transform(Xtrain_nonimg)\n",
    "Xtrain_img = scaler2.transform(Xtrain_img)\n",
    "Xtrain_img = normalizer2.transform(Xtrain_img)\n",
    "\n",
    "Xtest_nonimg = scaler1.transform(Xtest_nonimg)\n",
    "Xtest_nonimg = normalizer1.transform(Xtest_nonimg)\n",
    "Xtest_img = scaler2.transform(Xtest_img)\n",
    "Xtest_img = normalizer2.transform(Xtest_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifiers\n",
    "clf1 = MLPClassifier(solver='lbfgs', activation='logistic')\n",
    "#clf1 = MLPClassifier(solver='lbfgs', activation='logistic', hidden_layer_sizes=(20000))\n",
    "clf2 = MLPClassifier(solver='lbfgs', activation='logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit data\n",
    "clf1.fit(Xtrain_nonimg, ytrain_nonimg)\n",
    "clf2.fit(Xtrain_img, ytrain_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.568888888889\n",
      "0.602962962963\n"
     ]
    }
   ],
   "source": [
    "#Predict\n",
    "ypred_nonimg = clf1.predict(Xtest_nonimg)\n",
    "ypred_img = clf2.predict(Xtest_img)\n",
    "\n",
    "print(accuracy_score(ytest_img, ypred_img))\n",
    "print(accuracy_score(ytest_nonimg, ypred_nonimg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight classifiers\n",
    "eclf = VotingClassifier(estimators=[('mlp1', clf1), ('mlp2', clf2)], voting='soft', weights=[1, 1])\n",
    "\n",
    "scaler1.fit(rawX)\n",
    "normalizer1.fit(rawX)\n",
    "\n",
    "y_pred = eclf.fit(rawX, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got estimator VotingClassifier(estimators=[('mlp1', MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n       hidden_layer_sizes=(100,), learning_rate='constant',\n       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n       nesterovs_m...True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n       verbose=False, warm_start=False))],\n         flatten_transform=None, n_jobs=1, voting='soft', weights=[1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-708d0143ddb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Test accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \"\"\"\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# Don't get num_samples from an ensembles length!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         raise TypeError('Expected sequence or array-like, got '\n\u001b[0;32m--> 108\u001b[0;31m                         'estimator %s' % x)\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__array__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got estimator VotingClassifier(estimators=[('mlp1', MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n       hidden_layer_sizes=(100,), learning_rate='constant',\n       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n       nesterovs_m...True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n       verbose=False, warm_start=False))],\n         flatten_transform=None, n_jobs=1, voting='soft', weights=[1, 1])"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "print(accuracy_score(Y, y_pred))\n",
    "print(classification_report(Y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
